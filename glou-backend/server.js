import express from 'express';
import cors from 'cors';
import dotenv from 'dotenv';
import { OpenAI } from 'openai';

dotenv.config();
const app = express();
app.use(cors());
app.use(express.json({ limit: '1mb' }));

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

app.post('/api/recommendation', async (req, res) => {
  const { answers } = req.body;
  const prompt = buildPrompt(answers);

  try {
    const chat = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo', // ðŸ” tu peux passer temporairement Ã  "gpt-3.5-turbo" si besoin
      temperature: 0.7,
      messages: [{ role: 'user', content: prompt }],
      timeout: 25000 // dÃ©lai max pour Ã©viter que Render coupe aprÃ¨s 30s
    });

    const result = chat.choices[0].message.content.trim();
    let response;

    try {
      response = JSON.parse(result);
    } catch {
      return res.status(500).json({ error: 'RÃ©ponse IA invalide' });
    }

    res.json(response);
  } catch (err) {
    console.error('âŒ Erreur OpenAI :', err.message);
    res.status(500).json({ error: 'Erreur IA' });
  }
});

function buildPrompt(answers) {
  const essentialInfo = answers.map((a) => `- ${a.question} : ${a.answer}`).join('\n');

  return `
Tu es un sommelier IA expert. En te basant sur les prÃ©fÃ©rences suivantes, propose un vin rÃ©ellement existant, facilement trouvable sur Vivino, et parfaitement adaptÃ© aux goÃ»ts de l'utilisateur. Formate ta rÃ©ponse en JSON, sans explication.

PrÃ©fÃ©rences :
${essentialInfo}

RÃ©ponds au format :

{
  "name": "Nom du vin",
  "description": "Phrase Ã©lÃ©gante qui donne envie",
  "grape": "CÃ©page principal",
  "country": "Pays",
  "price": "Fourchette de prix",
  "url": "Lien Vivino"
}
`.trim();
}

const port = process.env.PORT || 10000;
app.listen(port, () => {
  console.log(`âœ… Serveur actif sur http://localhost:${port}`);
});
